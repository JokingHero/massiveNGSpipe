library(data.table); library(ORFik); library(BiocParallel)
library(googlesheets4)
devtools::load_all("~/massiveNGSpipe/")
# Set up folder for pipeline
bio_dir <- dirname(config())[1]
project_dir <- file.path(bio_dir, "NGS_pipeline")
config <- pipeline_config(project_dir)

# Get datasets (TODO: Wrap json file into package)
rpfdb_studies <- as.data.table(jsonlite::fromJSON("~/rpfdb-studies.json"))
rpfdb_accessions <- trimws(rpfdb_studies[Species == "S.cerevisiae", ]$Study[c(1:15)]) # SacCer
non_rpfdb_studies <- c("GSE152850")
accessions <- c(rpfdb_accessions, non_rpfdb_studies)
#accessions <- trimws(rpfdb_studies[Species == "Human"]$Study)

# Step1: Get all metadata
metadata_done <- TRUE
if (!metadata_done) {
  all_SRA_metadata <- pipeline_metadata(accessions, config, TRUE)
  # Step2: Try to auto annotate
  all_SRA_metadata_RFP <- pipeline_metadata_annotate(all_SRA_metadata,
                                                     "Saccharomyces cerevisiae")
  complete_metadata <- file.path(project_dir, "RFP_FINAL_LIST.csv")
  if (file.exists(complete_metadata)) { # IF you have started before
    complete_metadata_dt <- fread(complete_metadata)
    new_studies <- !(all_SRA_metadata_RFP$study_accession %in%
                       complete_metadata_dt$study_accession)
    message("New samples to annotate: ", sum(new_studies))
    suppressWarnings(all_SRA_metadata_RFP[, STAGE := NULL])
    all_SRA_metadata_RFP <- rbind(complete_metadata_dt,
                                  all_SRA_metadata_RFP[new_studies,])

  }
  fwrite(all_SRA_metadata_RFP, file.path(config$project, "RFP_pre_manual_annotation.csv"))
  # Step3: Store as csv and open in google sheet and fix
  # Create a new sheet or use existing one
  #google_url <- gs4_create(name = "RFP_next_round_manual2.csv")
  google_url <- "https://docs.google.com/spreadsheets/d/18Y-WDvV_w0kTT3Xap4M5GZWpg39ZK-gUzzV7fuKbMvo/edit#gid=769582544"
  write_sheet(read.csv((file.path(config$project, "RFP_pre_manual_annotation.csv"))),
              ss = google_url,
              sheet = 1); browseURL(google_url)
  # Step4: Now, Check if it is valid (if not repeat step with new csv)
  sheet <- as.data.table(googlesheets4::read_sheet(google_url))
  finished <- pipeline_validate_metadata(sheet, config)
  if (!finished) {
    write_sheet(read.csv(file.path(config$project, "RFP_next_round_manual.csv")),
                ss = google_url,
                sheet = 1)
  }
}

pipelines <- pipeline_init_all(config) # Initialize pipeline configuration for all experiments
# REMEMBER! Set new flags if you added new pipelines that are done with certain steps!
set_flag_all(config, steps = names(config$flag)[seq(5)], pipelines) # Set up to step 5 done
#progress_report(pipelines, config) # Check that it worked correctly

#' Start the pipeline in background jobs and you can
#' get status report by running progress_report(pipelines, config) whenever you want
run_pipeline(pipelines, config, wait = 100, BPPARAM = bpparam())

#run_pipeline(pipelines, config, wait = 100, BPPARAM = SerialParam())
# TODO: GSE150375
