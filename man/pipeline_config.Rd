% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pipeline_config.R
\name{pipeline_config}
\alias{pipeline_config}
\title{Initial config setup}
\usage{
pipeline_config(
  project_dir = file.path(dirname(config)[1], "NGS_pipeline"),
  config = ORFik::config(),
  complete_metadata = file.path(project_dir, "RFP_FINAL_LIST.csv"),
  backup_metadata = file.path(project_dir, "ALL_BACKUP_LIST.csv"),
  temp_metadata = file.path(project_dir, "RFP_next_round_manual.csv"),
  google_url = default_sheets(project_dir),
  preset = "Ribo-seq",
  flags = pipeline_flags(project_dir, mode),
  flag_steps = config_substeps(names(flags), mode, preset),
  pipeline_steps = preset_pipelines(preset, mode),
  mode = c("online", "local")[1],
  delete_raw_files = mode == "online",
  parallel_conf = bpoptions(log = TRUE, stop.on.error = TRUE),
  logdir = file.path(project_dir, "log_pipeline"),
  BPPARAM = bpparam()
)
}
\arguments{
\item{project_dir}{where will specific pipeline outputs be put}

\item{config}{path, default \code{ORFik::config()}, where will
fastq, bam, references and ORFik experiments go}

\item{complete_metadata}{path, default: file.path(project_dir, "RFP_FINAL_LIST.csv")
Where should completed valid metadata be stored as csv?}

\item{google_url}{url or sheet object for google sheet to use. Set to NULL to
not use google sheet.}

\item{flags}{named character vector, with cut points, where can
the pipeline continue if it breaks? Is defined in combination with
'steps' argument that defines that actuall function called for each break point.
Increasing break points makes the pipeline run faster at the cost of more
resource usage.}

\item{flag_steps}{a list of subsets of flags that maps which flags are set in
each function in 'step'.}

\item{mode}{= c("online", "local")\link{1}. "online" will assume project IDs for
online repository (SRA, ENA, PRJ etc). Local means local folders as accessions.}

\item{delete_raw_files}{logical, default: mode == "online". If online do delete
raw fastq files after trim step is done, for local samples do not delete.
Set only to TRUE for mode local, if you have backups!}

\item{parallel_conf}{a bpoptions object, default:
\code{bpoptions(log =TRUE, stop.on.error = TRUE)}
Specific pipeline config for parallel settings and log directory}

\item{logdir}{= file.path(project_dir, "log_pipeline"),}

\item{BPPARAM}{= bpparam()}

\item{steps}{a list of functions, the functions called during 'run_pipeline'}
}
\value{
a list with a defined config
}
\description{
Set up all paths, functions to be run and flag directories.
Also adds parallel processing settings and google integration.
}
